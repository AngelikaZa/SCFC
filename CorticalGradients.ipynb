{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Function Coupling & Cortical Gradients\n",
    "\n",
    "- Author: A. Zarkali\n",
    "- Date of last update: 14/05/2020\n",
    "- Aim: Extract cortical-gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import brainspace\n",
    "from brainspace.gradient import GradientMaps\n",
    "from brainspace.datasets import load_fsa5, load_conte69, load_parcellation\n",
    "from brainspace.plotting import plot_hemispheres, plot_surf\n",
    "from brainspace.utils.parcellation import map_to_labels\n",
    "from brainspace.mesh import mesh_io as mio\n",
    "import vtk\n",
    "from pathlib import Path\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "import nibabel\n",
    "import nilearn\n",
    "from nilearn import datasets, plotting, input_data, signal, image # datasets: for fetching atlas\n",
    "import seaborn as sns\n",
    "from brainspace.null_models import SpinPermutations\n",
    "from brainspace.plotting import plot_hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Participant Lists\n",
    "# Load clinical information\n",
    "clin = pd.read_excel(r\"C:\\Users\\Angelika\\Dropbox\\PhD\\PAPERS\\Publications\\Structure-Function\\NatureComms\\SupplementaryData1\\Figure2\\Data\\ClinicalInformation.xlsx\")\n",
    "# Select controls only\n",
    "controls = clin[clin.PD==0].ParticipantNumber\n",
    "HighVis = clin[(clin.PD == 1) & (clin.PD_VisPerf == 0)].ParticipantNumber\n",
    "LowVis = clin[(clin.PD == 1) & (clin.PD_VisPerf == 1)].ParticipantNumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate template gradient\n",
    "\n",
    "This is necessary so all resulting gradients are aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define cortical only indeces / columns\n",
    "parcel = 401 ## parcellation cortical nodes + 1\n",
    "cols = [] \n",
    "for i in range(1, parcel):\n",
    "    cols.append(str(i))\n",
    "index = []\n",
    "for i in range(1,parcel):\n",
    "    index.append(i)\n",
    "num = [range(1,parcel)]\n",
    "labelsNum = np.array(num)\n",
    "labelsNum = labelsNum.reshape((parcel-1),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate group template gradient\n",
    "## This is necessary to align all individuals to the same template\n",
    "array = np.zeros((360, 360))\n",
    "data_folder = Path(r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\04_StructureFunction\\DATA\\STRUCTURE\")\n",
    "for i in range(0, len(controls)):\n",
    "    data = pd.read_csv(path, header=0, index_col=0)\n",
    "    array = array + data\n",
    "array = array / len(controls)\n",
    "outfile = root / \"Average_Connectome_400_controls.csv\"\n",
    "np.savetxt(outfile, array, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate template gradient\n",
    "# Create a GradientMaps object for the template\n",
    "Gt = GradientMaps(n_components=10, random_state=0, approach=\"dm\", kernel=\"normalized_angle\")\n",
    "# Apply to template data\n",
    "# Structural\n",
    "#template_file = Path(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/04_StructureFunction/DATA/STRUCTURE/Average_Connectome_400_Control.csv\")\n",
    "# Functional\n",
    "template_file = Path(r\"C:/Users/Angelika/Dropbox/PhD/EXPERIMENTS/04_StructureFunction/DATA/FUNCTION/Average_Connectome_400_bin.csv\")\n",
    "template_data = pd.read_csv(template_file, header=None)\n",
    "template_data = pd.DataFrame(template_data, index=index)\n",
    "template_data = template_data[index]\n",
    "#template_data = template_data.replace(np.inf, 0) # for functional connectome need to replace the inf values to 0\n",
    "Gt.fit(template_data.values, sparsity=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot eigenvalues of the average gradients for the template\n",
    "fig, ax = plt.subplots(1, figsize=(10, 5))\n",
    "ax.set_xlabel('Component Nb')\n",
    "ax.set_ylabel('Eigenvalue')\n",
    "colors = [\"grey\"]\n",
    "sns.set_palette(sns.color_palette(colors))\n",
    "sns.scatterplot(x=range(Gt.lambdas_.size), y=Gt.lambdas_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate and plot variance explained\n",
    "var = []\n",
    "for l in range(len(Gt.lambdas_)):\n",
    "    v = Gt.lambdas_[l] / sum(Gt.lambdas_)\n",
    "    var.append(v)\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(10, 5))\n",
    "sns.scatterplot(x=range(10), y=var)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save eigenvalues and variance explained\n",
    "np.savetxt(\"TemplateEigenvalues.txt\", Gt.lambdas_)\n",
    "np.savetxt(\"TemplateVariance.txt\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate individual gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a GradientMaps object for the individuals\n",
    "Gsub = GradientMaps(n_components=10, random_state=0, alignment=\"procrustes\", approach=\"dm\", kernel=\"normalized_angle\")\n",
    "# # Loop through control subjects and generate gradients\n",
    "\n",
    "## Root directory\n",
    "rootdir = Path(r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\04_StructureFunction\\DATA\")\n",
    "## Loop through\n",
    "grad1 = pd.DataFrame(data=np.zeros((400,0)))\n",
    "grad2 = pd.DataFrame(data=np.zeros((400,0)))\n",
    "for i in range(len(controls)):\n",
    "    # for structural\n",
    "#     filename = rootdir / \"STRUCTURE\" / All[i] / \"shaefer_connectome_norm_400.csv\"\n",
    "#     conn_matrix = pd.read_csv(filename, index_col=0) # for structural\n",
    "    # for functional\n",
    "    filename = rootdir / \"FUNCTION\" / str(controls[i] + \"func_bin.csv\")\n",
    "    conn_matrix = pd.read_csv(filename, index_col= 0) # for functional     \n",
    "    # exclude the subcortical regions   \n",
    "    conn_matrix = pd.DataFrame(conn_matrix, index=index)\n",
    "    conn_matrix = conn_matrix[cols] # cols for structural and index for functional data\n",
    "    conn_matrix = conn_matrix.replace([np.inf, np.nan], 0) # for functional data only need to replace inf values with 0 - diagonals\n",
    "    ## convert to np.array\n",
    "    conn_matrix = conn_matrix.values\n",
    "    #Ask for 10 gradients (default)\n",
    "    Gsub.fit([template_data.values, conn_matrix], sparsity=0) # no thresholding for structural connectomes as already sparse\n",
    "    grad1[str(controls[i])] = (Gsub.aligned_[1])[:,0]\n",
    "    grad2[str(controls[i])] = (Gsub.aligned_[1])[:,1]\n",
    "#     print(All[i])\n",
    "grad1 = grad1.transpose()\n",
    "grad2 = grad2.transpose()\n",
    "grad1.columns = [i for i in range(1,401)]\n",
    "grad2.columns = [i for i in range(1,401)]\n",
    "grad1.to_csv(\"FunctionalGradientOne.csv\")\n",
    "grad2.to_csv(\"FunctionalGradientTwo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the gradients as per node position (from smallest to largest)\n",
    "struct = pd.read_csv(r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\04_StructureFunction\\DATA\\GRADIENTS\\StructuralGradientTwo.csv\", index_col=0)\n",
    "func = pd.read_csv(r\"C:\\Users\\Angelika\\Dropbox\\PhD\\EXPERIMENTS\\04_StructureFunction\\DATA\\GRADIENTS\\FunctionalGradientTwo.csv\", index_col=0)\n",
    "struct = struct.transpose()\n",
    "func = func.transpose()\n",
    "\n",
    "for i in range(len(controls)):\n",
    "    sub = controls[i]\n",
    "    func[sub] = func[controls[i]].rank(method=\"max\")\n",
    "    struct[sub] = struct[controls[i]].rank(method=\"max\")\n",
    "func.to_csv(\"FunctionalGradientTwo_Rank.csv\")\n",
    "struct.to_csv(\"FunctionalGradientTwo_Rank.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
